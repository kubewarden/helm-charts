# This is a Rancher questions file
---
questions:
  # Audit checks:
  - variable: "auditScanner.enable"
    type: boolean
    default: false
    required: true
    label: Enable Background Audit check
    description: |
      The Background Audit Check looks at existing Kubernetes resources and
      periodically determines whether they are still compliant with regards to the
      policies that are currently defined.
    group: "Audit checks"
  - variable: "auditScanner.cronJob.schedule"
    type: string
    default: "*/60 * * * *"
    show_if: auditScanner.enable=true
    label: Schedule
    description: |
      Schedule of the Background Audit check. Follows the Unix-cron syntax.
    group: "Audit checks"
  - variable: "auditScanner.disableStore"
    show_if: auditScanner.enable=true
    type: boolean
    default: false
    label: Don't store (Cluster)PolicyReports in etcd
    description: |
      If true, (Cluster)PolicyReports are not stored in etcd but using an in-memory cache.
      Note that you may need to adjust `resources.auditScanner` when using the
      in-memory store.
    group: "Audit checks"
  - variable: "auditScanner.serviceAccountName"
    type: string
    default: "audit-scanner"
    show_if: auditScanner.enable=true
    label: ServiceAccount name
    description: |
      The default audit-scanner ServiceAccount is bound to the ClusterRoles
      "view" (allows read-only access to most objects in a namespace, does not
      allow viewing secrets, roles or role bindings), and "audit-scanner-cluster-role"
      (allows read-write to Kubewarden resources and PolicyReports).
    group: "Audit checks"
  - variable: "auditScanner.policyReporter"
    type: boolean
    default: false
    show_if: auditScanner.enable=true
    label: Enable Policy Reporter UI
    description: |
      Policy reporter is a UI to visualize the reports generated by Background
      Audit checks
    group: "Audit checks"
  - variable: "auditScanner.skipAdditionalNamespaces"
    type: array[
    show_if: auditScanner.enable=true
    label: Additional namespaces to skip from audit
    description: |
      Additional namespaces that the audit scanner will not scan.
    group: "Audit checks"
  - variable: "auditScanner.parallelNamespaces"
    type: integer
    default: 1
    required: false
    show_if: auditScanner.enable=true
    label: Number of Namespaces to be audited in parallel
    description: |
      The audit-scanner iterate over all the Namespaces in the cluster. This
      value controls how many Namespaces are audited at the same time.
    group: "Audit checks"
  - variable: "auditScanner.parallelResources"
    type: integer
    default: 100
    required: false
    show_if: auditScanner.enable=true
    label: Number of resources to be audited in parallel
    description: |
      The audit-scanner iterates over all the resources of a certain type found
      inside of a Namespace. This parameter controls how many resources are
      audited at the same time.

      For example, if a Namespace has 1000 Pods, and this value is set to 100,
      the audit-scanner will audit 100 Pods at the same time.
    group: "Audit checks"
  - variable: "auditScanner.parallelPolicies"
    type: integer
    default: 5
    required: false
    show_if: auditScanner.enable=true
    label: Number of policies to evaluate fora given resournce in parallel
    description: |
      For each specific resource, the audit-scanner evaluates all the policies
      that are interested about this kind of resource. This parameter controls
      how many policies are evaluated at the same time.

      For example, if 10 policies are interested in Pods, and this value is set
      to 5, the audit-scanner will evaluate 5 policies at the same time.
    group: "Audit checks"
  - variable: "auditScanner.pageSize"
    type: integer
    default: 100
    required: false
    show_if: auditScanner.enable=true
    label: Number of resources to fetch from the Kubernetes API server when paginating
    description: |
      When looking into a specific type of resource, audit-scanner fetches these objects
      in chunks. This parameter controls how many resources are fetched at the same time.
    group: "Audit checks"
  # controller HA:
  - variable: "replicas"
    type: integer
    default: 1
    required: true
    label: Number of replicas
    description: |
      Number of replicas of the Controller Deployment
    group: "Controller HA"
  - variable: "global.priorityClassName"
    type: string
    default: ""
    required: false
    label: Name of priorityClass
    description: |
      Name of the priorityClass to apply to the Kubewarden controller.
    group: "Controller HA"
  # OpenTelemetry:
  - variable: "telemetry.mode"
    type: enum
    options:
      - "sidecar"
      - "custom"
    default: "sidecar"
    required: true
    label: Telemetry mode
    description: |
      Choose the telemetry mode. 
      Sidecar mode will deploy an OpenTelemetry Collector as a sidecar container in the Kubewarden Controller pod. 
      Custom mode will allow you to configure the OpenTelemetry Collector by your own and Kubewarden will send data to it.
    group: "OpenTelemetry"
  - variable: "telemetry.metrics"
    type: boolean
    default: false
    required: true
    label: Enable Metrics
    description: |
      Enable metrics collection for all Policy Servers and the Kubewarden Controller.
      Important: Requires OpenTelemetry CRDs available.
    group: "OpenTelemetry"
  - variable: "telemetry.sidecar.metrics.port"
    type: string
    default: "8080"
    label: Port
    description: |
      Port of the Prometheus exporter and PolicyServer metrics service.
    group: "OpenTelemetry"
    show_if: "telemetry.mode=sidecar && telemetry.metrics=true"
  - variable: "telemetry.tracing"
    type: boolean
    default: false
    required: true
    label: Enable Tracing
    description: |
      Enable tracing collection for all PolicyServers.
      Important: Requires OpenTelemetry CRDs available.
    group: "OpenTelemetry"
  - variable: "telemetry.sidecar.tracing.jaeger.endpoint"
    type: string
    default: my-open-telemetry-collector.jaeger.svc.cluster.local:4317
    label: Jaeger endpoint configuration
    description: |
      Configuration of the OTLP/Jaeger exporter.
    group: "OpenTelemetry"
    show_if: "telemetry.mode=sidecar && telemetry.tracing=true"
  - variable: "telemetry.sidecar.tracing.jaeger.tls.insecure"
    type: boolean
    default: false
    label: Jaeger endpoint insecure TLS configuration
    description: |
      Important: Insecure, not for production usage.
    group: "OpenTelemetry"
    show_if: "telemetry.mode=sidecar && telemetry.tracing=true"
  - variable: "telemetry.custom.endpoint"
    type: string
    default: ""
    label: OpenTelemetry endpoint
    description: |
      Endpoint of the OpenTelemetry collector.
    group: "OpenTelemetry"
    show_if: "telemetry.mode=custom"
  - variable: "telemetry.custom.insecure"
    type: boolean
    default: false
    label: Insecure communication
    description: |
      Disable TLS verification for the OpenTelemetry collector.
    group: "OpenTelemetry"
    show_if: "telemetry.mode=custom"
  - variable: "telemetry.custom.otelCollectorCertificateSecret"
    type: string
    default: ""
    label: Certificate secret
    description: |
      Secret containing the certificate for the OpenTelemetry collector.
      The secret should contain the key `ca.crt`.
    group: "OpenTelemetry"
    show_if: "telemetry.mode=custom && telemetry.custom.insecure=false"
  - variable: "telemetry.custom.otelCollectorClientCertificateSecret"
    type: string
    default: ""
    label: Client certificate secret
    description: |
      Secret containing the client certificate for the OpenTelemetry collector (mTLS).
      The secret should contain the keys `tls.crt` and `tls.key`.
    group: "OpenTelemetry"
    show_if: "telemetry.mode=custom && telemetry.custom.insecure=false"
